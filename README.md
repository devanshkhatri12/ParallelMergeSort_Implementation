# ğŸš€ Multithreaded Merge Sort â€” Faster Sorting with Parallelism

Sorting is fundamental to computer science, and classic algorithms like Merge Sort already deliver an efficient O(n log n) time complexity. But can we push this further using parallelism?

This project explores that idea by implementing:

    âœ… A Single-Threaded Merge Sort.
    âœ… A Parallel Merge Sort using std::thread
    âœ… Benchmarks on arrays up to 10 million elements

The goal is to observe how multithreading affects execution time, where it helps, and where it causes overhead.


# ğŸ§  Why Multithread Merge Sort?

Merge Sort follows a divide-and-conquer strategy:

1. Split the array into two halves
2. Recursively sort each half
3. Merge the two sorted halves

This splitting phase makes Merge Sort naturally parallelizable because:

- Sub-arrays are independent.
- No shared memory â†’ no locks needed.
- Workload can be distributed across CPU cores.

However, blindly creating threads at every recursion level can:

- Exhaust OS thread limits.
- Increase context-switch overhead.
- Slow down sorting for small arrays.

To handle this, the project uses a depth threshold where recursion below a certain size falls back to the normal merge sort.

# âš™ï¸ Features

    âœ… Fully implemented Single-Threaded Merge Sort
    âœ… Fully implemented Parallel Merge Sort using std::thread
    âœ… Dynamic threading limit to avoid thread explosion
    âœ… Benchmarking support with std::chrono
    âœ… Support for very large arrays (10M+)
    âœ… Clean object-oriented design
    âœ… Works on MSYS2 / MinGW-w64 / Linux / macOS.

# ğŸ—ï¸ Project Structure

```
/project
    â”‚â”€â”€ mergeSort.hpp
    â”‚â”€â”€ mergeSort.cpp
    â”‚â”€â”€ parallelMergeSort.hpp
    â”‚â”€â”€ parallelMergeSort.cpp
    â”‚â”€â”€ main.cpp
    â”‚â”€â”€ README.md
```

# ğŸ§µ How Parallel Merge Sort Works

âœ… Thread Creation Strategy

- For large array segments â†’ create a new thread for one half
- For smaller segments â†’ fallback to normal merge sort (avoids overhead)
- Uses CPU cores efficiently without exploding thread count

âœ… No Mutex Needed

Each recursive call processes its own subarray, so there's no shared data race.

âœ… Parallel Merge

After two child threads finish, both halves are sorted and merged normally.


## ğŸ“Š Updated Benchmark Results (Your Machine Recommended)

You can replace the below table with your own system's output.

### âœ… Example Benchmark (Based on C++ Implementation)

| Input Size   | Single-Threaded (t1) | Multi-Threaded (t2) | Faster Approach | Speedup |
|--------------|-----------------------|----------------------|-----------------|---------|
| 1,000        | 0.0011 s              | 0.0013 s             | Single Thread   | -13%    |
| 10,000       | 0.0136 s              | 0.0055 s             | Multi Thread    | +147%   |
| 100,000      | 0.1599 s              | 0.0378 s             | Multi Thread    | +222%   |
| 1,000,000    | 1.6211 s              | 0.3103 s             | Multi Thread    | +422%   |
| 10,000,000   | 18.2698 s             | 2.8734 s             | Multi Thread    | +535%   |

âœ… **Multithreading wins massively for large input sizes**  
âŒ **Overhead dominates for tiny inputs (1000 elements)**  


# â–¶ï¸ How to Compile

### âœ… Using g++ (MSYS2, Linux, Mac)




# ğŸ“ˆ What You Can Modify

    âœ… Change thread threshold
    âœ… Add thread pool implementation
    âœ… Try using std::async instead of threads
    âœ… Compare with OpenMP parallel merge sort

# ğŸ“ Conclusion

This project demonstrates that:

    âœ… Merge Sort parallelizes extremely well
    âœ… Multithreading drastically reduces sorting time for large arrays
    âŒ Small arrays suffer due to thread-creation overhead
    âœ… CPU core count heavily influences performance
    âœ… Adaptive threading (threshold-based) gives best results

It is a practical demonstration of real-world parallelism, where algorithm design must balance CPU power, overheads, and workload distribution.


